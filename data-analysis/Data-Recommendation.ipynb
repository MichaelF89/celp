{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data\n",
    "\n",
    "Korte data analyse voor het verkenne van de yelp data voor het verslag van week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity, manhattan_distances, euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file loads the data from the data directory and shows you how.\n",
    "Feel free to change the contents of this file!\n",
    "Do ensure these functions remain functional:\n",
    "    - get_business(city, business_id)\n",
    "    - get_reviews(city, business_id=None, user_id=None, n=10)\n",
    "    - get_user(username)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "\n",
    "def load_cities():\n",
    "    \"\"\"\n",
    "    Finds all cities (all directory names) in ./data\n",
    "    Returns a list of city names\n",
    "    \"\"\"\n",
    "    return os.listdir(DATA_DIR)\n",
    "\n",
    "\n",
    "def load(cities, data_filename):\n",
    "    \"\"\"\n",
    "    Given a list of city names,\n",
    "        for each city extract all data from ./data/<city>/<data_filename>.json\n",
    "    Returns a dictionary of the form:\n",
    "        {\n",
    "            <city1>: [<entry1>, <entry2>, ...],\n",
    "            <city2>: [<entry1>, <entry2>, ...],\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for city in cities:\n",
    "        city_data = []\n",
    "        with open(f\"{DATA_DIR}/{city}/{data_filename}.json\", \"r\") as f:\n",
    "            for line in f:\n",
    "                city_data.append(json.loads(line))\n",
    "        data[city] = city_data\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_business(city, business_id):\n",
    "    \"\"\"\n",
    "    Given a city name and a business id, return that business's data.\n",
    "    Returns a dictionary of the form:\n",
    "        {\n",
    "            name:str,\n",
    "            business_id:str,\n",
    "            stars:str,\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    for business in BUSINESSES[city]:\n",
    "        if business[\"business_id\"] == business_id:\n",
    "            return business\n",
    "    raise IndexError(f\"invalid business_id {business_id}\")\n",
    "\n",
    "\n",
    "def get_reviews(city, business_id=None, user_id=None, n=10):\n",
    "    \"\"\"\n",
    "    Given a city name and optionally a business id and/or auser id,\n",
    "    return n reviews for that business/user combo in that city.\n",
    "    Returns a dictionary of the form:\n",
    "        {\n",
    "            text:str,\n",
    "            stars:str,\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    def should_keep(review):\n",
    "        if business_id and review[\"business_id\"] != business_id:\n",
    "            return False\n",
    "        if user_id and review[\"user_id\"] != user_id:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    reviews = REVIEWS[city]\n",
    "    reviews = [review for review in reviews if should_keep(review)]\n",
    "    return random.sample(reviews, min(n, len(reviews)))\n",
    "\n",
    "\n",
    "def get_user(username):\n",
    "    \"\"\"\n",
    "    Get a user by its username\n",
    "    Returns a dictionary of the form:\n",
    "        {\n",
    "            user_id:str,\n",
    "            name:str,\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    for city, users in USERS.items():\n",
    "        for user in users:\n",
    "            if user[\"name\"] == username:\n",
    "                return user\n",
    "    raise IndexError(f\"invalid username {username}\")\n",
    "\n",
    "\n",
    "CITIES = load_cities()\n",
    "USERS = load(CITIES, \"user\")\n",
    "BUSINESSES = load(CITIES, \"business\")\n",
    "REVIEWS = load(CITIES, \"review\")\n",
    "TIPS = load(CITIES, \"tip\")\n",
    "CHECKINS = load(CITIES, \"checkin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Schoonmaken BUSINESSES'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Schoonmaken BUSINESSES'''\n",
    "#business = citymerge(BUSINESSES)\n",
    "#business = business[business['is_open'] == 1 & business['categories'].notna()]\n",
    "#business['categories'] = business['categories'].str.split(', ')\n",
    "#print(business.latitude.mean(), business.longitude.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om data van alle steden samen te voegen in 1 DataFrame\n",
    "def citymerge(var):\n",
    "    return pd.concat([pd.DataFrame(var[city]) for city in var]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY = 'westlake'\n",
    "reviews = pd.read_json(DATA_DIR+'/'+CITY+'/review.json', lines=True)\n",
    "businesses = pd.read_json(DATA_DIR+'/'+CITY+'/business.json', lines=True)\n",
    "#businesses = citymerge(BUSINESSES)\n",
    "reviews_train, reviews_test = train_test_split(reviews)#citymerge(REVIEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creeer Utility Matrix en Mean Utility Matrix uit een variabele van data.py (REVIEWS, USERS, BUSINESSES, etc.)\n",
    "def create_utility_matrix(df):\n",
    "\n",
    "    utility_matrix  = pd.pivot_table(df, index='business_id', columns='user_id', values='stars')\n",
    "\n",
    "    mean_ultility_matrix = utility_matrix - utility_matrix.mean()\n",
    "    \n",
    "    return utility_matrix, mean_ultility_matrix\n",
    "    \n",
    "utility_matrix, mean_utility_matrix = create_utility_matrix(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_similarity(matrix, id1, id2):\n",
    "    \"\"\"Compute manhattan similarity between two rows.\"\"\"\n",
    "    # compute distance\n",
    "    distance = manhattan_distances(matrix, id1, id2)\n",
    "    \n",
    "    # if no distance could be computed (no shared features) return a similarity of 0\n",
    "    if distance is np.nan:\n",
    "        return 0\n",
    "    \n",
    "    # else return similarity\n",
    "    return 1 / (1 + distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creeer Similarity Matrix uit Mean Utility Matrix\n",
    "def similarity(mum):\n",
    "    similarity_matrix_cosine = pd.DataFrame(cosine_similarity(mum.fillna(0)), index=mum.index, columns=mum.index).replace(0, np.nan)\n",
    "    similarity_matrix_manhattan = 1 / (pd.DataFrame(manhattan_distances(mum.fillna(0)), index=mum.index, columns=mum.index).replace(0, np.nan) +1)\n",
    "    similarity_matrix_euclidean = 1 / (pd.DataFrame(euclidean_distances(mum.fillna(0)), index=mum.index, columns=mum.index).replace(0, np.nan) +1)\n",
    "    \n",
    "    return similarity_matrix_cosine, similarity_matrix_manhattan, similarity_matrix_euclidean   \n",
    "    \n",
    "similarity_matrix_cosine, similarity_matrix_manhattan, similarity_matrix_euclidean = similarity(mean_utility_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "business_id\n",
       "ZTg8adZipR3QDoJmFZZqJw    1.000000\n",
       "eigkQ_PuRON8Se265NqQDQ    0.041096\n",
       "oZH3Ee7Yjk7u8B4Ed0oVOg    0.040008\n",
       "r0DureDzsHpzs_VZem5k7g    0.037465\n",
       "irwDkp2eMP2x-4MfunRt8g    0.035356\n",
       "EpJhRvkGDFE-GDPHM32klw    0.034690\n",
       "PzuyoHj3-VrYK7N8ZestNA    0.032788\n",
       "dVvij7VRh55dISu02I0IGw    0.028460\n",
       "5MWWP4Kpmw0e8d2ib9G7Kg    0.027826\n",
       "47me-6Zme7RYR0zEonfaHg    0.019205\n",
       "0VJ8tBxOpD2OxuioVjaAxA    0.015957\n",
       "spjaRNFn9Lmh4petKBuf5g    0.001452\n",
       "Name: ZTg8adZipR3QDoJmFZZqJw, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_neighborhood(similarity_matrix, utility_matrix, target_user, target_business):\n",
    "    \"\"\"selects all items with similarity > 0\"\"\"\n",
    "    # Controleer of target_user en target_business wel in de matrix zijn te vinden.\n",
    "    if (target_business in similarity_matrix.index) and (target_user in utility_matrix.columns):\n",
    "\n",
    "        # Maak een boolean mask van bedrijven die de gebruiker beoordeeld heeft met een similarity hoger dan 0.\n",
    "        SelectedBusinesses = (similarity_matrix[target_business].index.isin(utility_matrix[target_user].dropna().index)) & (similarity_matrix[target_business] > 0)\n",
    "    \n",
    "        # return de bedrijven met de similarity door gebruik te maken van de eerder gecreeerde boolean mask.\n",
    "        return similarity_matrix[target_business][SelectedBusinesses].sort_values(ascending = False)\n",
    "    \n",
    "    # Bij waarden die niet gevonden kunnen worden geef None terug.\n",
    "    else:\n",
    "        return pd.Series()\n",
    "\n",
    "%time neighborhood = select_neighborhood(similarity_matrix, utility_matrix, 'e3fdrK1tMCwWLr76LFe-cA', 'ZTg8adZipR3QDoJmFZZqJw')\n",
    "display(neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.885708870994802\n"
     ]
    }
   ],
   "source": [
    "def weighted_mean(neighborhood, utility_matrix, user_id):\n",
    "    # Controleer of neighborhood wel een Series is en utility_matrix wel een DataFrame, anders return np.nan.\n",
    "    if isinstance(neighborhood, pd.Series) and isinstance(utility_matrix, pd.DataFrame):\n",
    "        # Als neighborhood of de utility_matrix leeg zijn return dan 0.\n",
    "        if (neighborhood.empty) or (utility_matrix.empty):\n",
    "            return np.nan\n",
    "        \n",
    "        # Controleer of user_id als kolom te vinden is, anders return 0.\n",
    "        elif user_id in utility_matrix.columns:\n",
    "    \n",
    "            # Gebruik de bovenstaande formule om het gewogen gemiddelde voor de neighborhood te berekenen.\n",
    "            return ((utility_matrix[user_id] * neighborhood).dropna().sum()) / (neighborhood.sum())\n",
    "\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "prediction = weighted_mean(neighborhood, utility_matrix, 'e3fdrK1tMCwWLr76LFe-cA')\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspel een score voor bedrijven en return deze als dict\n",
    "def predictions(utility_matrix, similarity_matrix, user_id):\n",
    "    predictdict = defaultdict()\n",
    "    \n",
    "    # Extract list of reviewed businesses to get new results\n",
    "    review_list = utility_matrix[user_id][utility_matrix[user_id].notna()].index\n",
    "    \n",
    "    for business_id in similarity_matrix.index:\n",
    "        if business_id in review_list:\n",
    "            pass\n",
    "        else:\n",
    "            predictdict[business_id] = weighted_mean(select_neighborhood(similarity_matrix, utility_matrix, user_id, business_id), utility_matrix, user_id)\n",
    "    \n",
    "    return predictdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 842 ms\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "# display(pd.read_json(DATA_DIR+'/'+CITY+'/user.json', lines=True).head())\n",
    "# reviews[reviews['user_id'] == 'apP3CApEq6-z59tRLwEBYA']['business_id']\n",
    "\n",
    "def predictions_combiner(ibcf_predictions, cb_predictions, ibcf_weight=0.8, reviews=reviews_train, businesses=businesses):\n",
    "    hybrid_predictions = {}\n",
    "    cb_weight = 1 - ibcf_weight\n",
    "    for business_id in cb_predictions:\n",
    "        if business_id in ibcf_predictions:\n",
    "            ibcf_prediction = ibcf_predictions[business_id]\n",
    "            cb_prediction = cb_predictions[business_id]\n",
    "            hybrid_predictions[business_id] = ibcf_prediction*ibcf_weight + cb_prediction*cb_weight\n",
    "            if ibcf_prediction == np.nan:\n",
    "                hybrid_predictions[business_id] = cb_prediction\n",
    "            if cb_prediction == np.nan:\n",
    "                hybrid_predictions[business_id] = ibcf_prediction\n",
    "        else:\n",
    "            hybrid_predictions[business_id] = cb_prediction\n",
    "            \n",
    "    return  dict(sorted(hybrid_predictions.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    \n",
    "def content_based_recommender(user_id, businesses=businesses):\n",
    "    predicted_ratings = {}\n",
    "    category_dict = make_category_dict(user_id)\n",
    "    for business_id in businesses['business_id']:\n",
    "        predicted_ratings[business_id] = content_based_predictor(user_id, business_id, category_dict)\n",
    "    return predicted_ratings\n",
    "    \n",
    "def content_based_predictor(user_id, business_id, category_dict, reviews=reviews_train, businesses=businesses):\n",
    "    ratings = []\n",
    "    categories = businesses[businesses['business_id'] == business_id]['categories'].str.split(', ')\n",
    "    for x in categories:\n",
    "        for category in x:\n",
    "            if category in category_dict:\n",
    "                ratings.append(category_dict[category])\n",
    "    if len(ratings) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return sum(ratings)/len(ratings)\n",
    "        \n",
    "def make_category_dict(user_id, reviews=reviews, businesses=businesses):\n",
    "    category_dict = {}\n",
    "    user_reviews = reviews[reviews['user_id'] == user_id]\n",
    "    business_ids = user_reviews['business_id']\n",
    "    for business_id in business_ids:\n",
    "        categories = businesses[businesses['business_id'] == business_id]['categories'].str.split(', ')\n",
    "        stars = user_reviews[user_reviews['business_id'] == business_id]['stars'].values[0]\n",
    "        for x in categories:\n",
    "            for category in x:\n",
    "                if category in category_dict:\n",
    "                    category_dict[category].append(stars)\n",
    "                else:\n",
    "                    category_dict[category] = [stars]\n",
    "    for category in category_dict:\n",
    "        category_dict[category] = sum(category_dict[category])/len(category_dict[category])\n",
    "    return category_dict\n",
    "\n",
    "%time cb_predictions = content_based_recommender('e3fdrK1tMCwWLr76LFe-cA')\n",
    "%time ibcf_predictions = predictions(utility_matrix, similarity_matrix, 'e3fdrK1tMCwWLr76LFe-cA')\n",
    "# cb_predictions\n",
    "# ibcf_predictions\n",
    "# only_icbf = predictions_combiner(ibcf_predictions, cb_predictions)\n",
    "all_predictions = predictions_combiner(ibcf_predictions, cb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zq4i9ZtLebbvyWjKXec3NQ',\n",
       " 'i7lFu1-iadoXW5Hn-JWaeg',\n",
       " 'VZKWW2zQbk-rxwpAcque8w',\n",
       " 'OD88wvH-9LxM_Gz4oHOIDg',\n",
       " '9vsqbJgjUqQNJpHrSj6jKw',\n",
       " 'pIBX_IBixagX-2AzFPl77g',\n",
       " 'LhW7pWkVgu_bAMiRhO3Wow',\n",
       " 'UT0FUBRmpnGHE1U4Jpegxw',\n",
       " '-MsRvdPnuw6QuLn5Vxjruw',\n",
       " 'yBPeUobSSaJQKaYYgiOKYA']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_items(predictions):\n",
    "    pool = []\n",
    "    safety = 0\n",
    "    average = sum(list(predictions.values())[0:10])/10\n",
    "    average -= 0.1 * average\n",
    "    for prediction in predictions:\n",
    "        if predictions[prediction] > average:\n",
    "            pool.append(prediction)\n",
    "        else:\n",
    "            break\n",
    "    if len(pool) < 10:\n",
    "        pool = list(predictions.keys())[0:10]\n",
    "    return random.sample(pool, k=10)\n",
    "\n",
    "select_items(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i7lFu1-iadoXW5Hn-JWaeg    4.000000\n",
       "nYvBZYg9rfqWFTYuxSVMdw    3.716189\n",
       "2lcK3d4K7FU6O8wXdWzOmA    3.418317\n",
       "mW28NmePxX7pZv8lCv7v2Q    3.384202\n",
       "0ZN2MfHyjNIkCx7qJvVhDg    3.359787\n",
       "KR2kRmHnRCaNzOUEGoB25w    2.766890\n",
       "LhW7pWkVgu_bAMiRhO3Wow    3.900000\n",
       "K5iqS0JXnKFFujZHIWQsag    3.233669\n",
       "UT0FUBRmpnGHE1U4Jpegxw    3.900000\n",
       "_v7lMUtdd6WlgKUEBLA_VA    3.043494\n",
       "QcW0360vpeEilCLBlKEiLw    3.205307\n",
       "IYZ5TSguf72Pq-ZJzZu0WQ    3.100000\n",
       "bzdb1jJ1j8Qn_RVHY97FnA    3.001130\n",
       "7dlCzYnXDaubTAfvgAX6sQ    3.446210\n",
       "z58nyUVyDV-vC7nXFfvR5g    2.524324\n",
       "op0sZT-TNyeTMw0m3HUUDQ    4.000000\n",
       "5kCRty4p7tBwM9P7MAXgvA    3.591778\n",
       "kkNWzhSpAjxm0zIxol3IzQ    3.848649\n",
       "95Efv0xKoUsP5lvTnaeK5w    3.738281\n",
       "x5lN8HdgDVWXwoL9N7MDoQ    3.564828\n",
       "hTdV1_Xn1j6yhpIR7CgCJQ    4.282431\n",
       "t10X85k_m8RuAZZgoMzvXg    4.000000\n",
       "vkD7xW81EgCSWwiTvxtVAw    3.871036\n",
       "EpJhRvkGDFE-GDPHM32klw    3.781081\n",
       "SPb3oLIVZynmiS670Vo1kQ    3.547710\n",
       "m9Cme6bUPuZFtqhN1AgmdQ    3.519102\n",
       "b--I9Ed6N5P9fwEb2qaiqg    3.170135\n",
       "BsLxCm_DMxCNVEPHoaj8hw    3.131985\n",
       "yG9SpxEQVIhk6e1o3jbSKg    3.113973\n",
       "axGP6FXAZlBdmdN9juu1tQ    3.104543\n",
       "                            ...   \n",
       "mY9tk1ZVMf9Zco9SaXMk6Q    3.719019\n",
       "qlsAl7z4NYuf7CVpF2BJcw    2.124324\n",
       "REfekXeUbPWGkgvlzSNbpw    3.412631\n",
       "v4WFgb4_rxCyfX1aG6eCZw    3.089926\n",
       "MWcN6qLWTfRJqLySxwJNqQ    3.072772\n",
       "6tK-R3BQ-GiMxsCGtxpJyw    4.333333\n",
       "j_oKMbKv4vlkyRxD9p1fKA    4.066667\n",
       "y_hf7TO6b6-VkxjhV9cqyA    3.878438\n",
       "aRmNacukkGh7n_geAbb7oA    3.762517\n",
       "oZH3Ee7Yjk7u8B4Ed0oVOg    3.440227\n",
       "irwDkp2eMP2x-4MfunRt8g    3.440227\n",
       "5rb2tq_AhxQuRYu_bh464g    3.371622\n",
       "I_eSnGmk5nDdsOL6Y4OAEg    3.342373\n",
       "akRtfcCezswizRIaAqJ4fQ    2.982883\n",
       "SA4ZV8JInv9IkW7L8O7JlA    2.949134\n",
       "Scub4d_tTkdD7g7QxcaaGg    3.871772\n",
       "3NuQdQQdLV9de4GODl_cUA    3.856731\n",
       "kts54mVKhgMvU_qDsXCCpw    3.782635\n",
       "8_9NeKvvJVaDZyhwchKM-w    3.307243\n",
       "U1sdC4OHzPuLpl0ZY3YcPw    3.180660\n",
       "EiVYrgOqG3Y9Ef9_ApZi4A    3.107658\n",
       "rcoAajAVBBXsBNfgKYaH-w    4.108984\n",
       "vfsbLhXGiXm8lqI12abrbQ    2.910873\n",
       "He6gCZdGICRXw-G7IusxBA    4.709550\n",
       "I_RkxalxylAoseHesrgfJw    3.620757\n",
       "PHceo653FqAeQHHrvvaMjA    3.163214\n",
       "ImbjRcr33wAm6o1ShWecpg    2.553591\n",
       "1pz_bSQXV4od4d8H0znV7g    2.550000\n",
       "iytPyg_lc_cBb3id1oaDGA    3.441585\n",
       "gIroxzbCiNsn9qIhpGDf0Q    3.846091\n",
       "Length: 134, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(all_predictions).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\python\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity MSE: 0.06741598823202663\n",
      "Manhattan Similarity MSE: 0.6377814623080322\n",
      "Cosine Similarity MSE: 0.6331693729793064\n"
     ]
    }
   ],
   "source": [
    "def predict_ratings_item_based(similarity, utility, test_data):\n",
    "    # For loop door alle index waarden\n",
    "    for ID in test_data.index:\n",
    "        # Bereken neighbourhood\n",
    "        neighborhood = select_neighborhood(similarity, utility, test_data.loc[ID, 'user_id'], test_data.loc[ID, 'business_id'])\n",
    "        # Voeg het gewogen gemiddelde toe als predicted rating aan de test_data Dataframe\n",
    "        test_data.loc[ID, 'predicted rating'] = weighted_mean(neighborhood, utility, test_data.loc[ID, 'user_id'])\n",
    "    \n",
    "    return test_data\n",
    "    \n",
    "predicted_item_based_cosine = predict_ratings_item_based(similarity_matrix_cosine, utility_matrix, review_test[['user_id', 'business_id', 'stars']])\n",
    "predicted_item_based_manhattan = predict_ratings_item_based(similarity_matrix_manhattan, utility_matrix, review_test[['user_id', 'business_id', 'stars']])\n",
    "predicted_item_based_euclidean = predict_ratings_item_based(similarity_matrix_euclidean, utility_matrix, review_test[['user_id', 'business_id', 'stars']])\n",
    "\n",
    "def mse(predicted_ratings):\n",
    "    # Bereken mse uit de formule hierboven\n",
    "    return ((predicted_ratings['stars'] - predicted_ratings['predicted rating']).pow(2).sum()) / (predicted_ratings.shape[0])\n",
    "    \n",
    "print('Cosine Similarity MSE: '+str(mse(predicted_item_based_cosine)))\n",
    "print('Manhattan Similarity MSE: '+str(mse(predicted_item_based_manhattan)))\n",
    "print('Cosine Similarity MSE: '+str(mse(predicted_item_based_euclidean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>e3fdrK1tMCwWLr76LFe-cA</td>\n",
       "      <td>cbjF6szaq2orE0BplGAKEA</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14487</th>\n",
       "      <td>e3fdrK1tMCwWLr76LFe-cA</td>\n",
       "      <td>5rb2tq_AhxQuRYu_bh464g</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>e3fdrK1tMCwWLr76LFe-cA</td>\n",
       "      <td>irwDkp2eMP2x-4MfunRt8g</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>e3fdrK1tMCwWLr76LFe-cA</td>\n",
       "      <td>r0DureDzsHpzs_VZem5k7g</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>e3fdrK1tMCwWLr76LFe-cA</td>\n",
       "      <td>EpJhRvkGDFE-GDPHM32klw</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>e3fdrK1tMCwWLr76LFe-cA</td>\n",
       "      <td>r0DureDzsHpzs_VZem5k7g</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id             business_id  stars\n",
       "7076   e3fdrK1tMCwWLr76LFe-cA  cbjF6szaq2orE0BplGAKEA    3.0\n",
       "14487  e3fdrK1tMCwWLr76LFe-cA  5rb2tq_AhxQuRYu_bh464g    5.0\n",
       "13902  e3fdrK1tMCwWLr76LFe-cA  irwDkp2eMP2x-4MfunRt8g    4.0\n",
       "11987  e3fdrK1tMCwWLr76LFe-cA  r0DureDzsHpzs_VZem5k7g    3.0\n",
       "9027   e3fdrK1tMCwWLr76LFe-cA  EpJhRvkGDFE-GDPHM32klw    3.0\n",
       "12002  e3fdrK1tMCwWLr76LFe-cA  r0DureDzsHpzs_VZem5k7g    4.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = review_test[['user_id', 'business_id', 'stars']]\n",
    "test[test['user_id'] == 'e3fdrK1tMCwWLr76LFe-cA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07891086730088631\n"
     ]
    }
   ],
   "source": [
    "def predict_ratings_content_based(test_data):\n",
    "    # For loop door alle index waarden\n",
    "    for ID in test_data.index:\n",
    "        # Bereken neighbourhood\n",
    "        category_dict = make_category_dict(test_data.loc[ID, 'user_id'])\n",
    "        test_data.loc[ID, 'predicted rating'] = content_based_predictor(test_data.loc[ID, 'user_id'], test_data.loc[ID, 'business_id'], category_dict)\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "predicted_content_based = predict_ratings_content_based(review_test[['user_id', 'business_id', 'stars']])\n",
    "\n",
    "print (mse(predicted_content_based))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
